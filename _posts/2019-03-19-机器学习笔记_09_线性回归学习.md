---
title: 机器学习笔记_09_线性回归学习
categories:
- ML
tags:
- tensorflow
updated: 2019-03-19
---



 

笔记来源：培训视频       tensorflow_线性回归学习

**tensorflow运算：**

   		**矩阵运算： tf.matmul(x,w)**

​		**平方： tf.square(error)**

​		**均值： tf.reduce_mean(error)**

**梯度下降：**

​	**tf.train.GradientDescentOptimizer(learning_rate)**

​	**梯度下降优化**

​	**learning_rate:学习率，一般为**
	**method:**

​	**minmize(loss)**

​	**return:梯度下降op**

```
trainable参数：指定这个变量能跟着梯度下降一起优化
```

```
学习率不能太大，太大的话，梯度爆炸，太小的话，步数太少的话，达不到效果
```

关于梯度爆炸/梯度消失：

在极端情况下，权重的值变得非常大，以至于溢出，导致NaN值

如何解决梯度爆炸问题（深度神经网络（RNN等）当中更容易出现

​	1.重新涉及网络

​	2.调整学习率

​	3.使用梯度截断（在训练过程中检查和限制梯度的大小）
	4.使用激活函数



<img src="{{ site.url }}/assets//blog_images/ML/线性回归学习_01.png" />

一次优化后的结果：

```python
# coding: utf-8
import tensorflow as tf


def myregression():

    # 1.准备数据，x 特征值[100,1] y目标值[100]
    x = tf.random_normal([100,1], mean=1.75,stddev=0.5,name='x_data')
    # 矩阵相乘必须是二维的
    y_true = tf.matmul(x,[[0.7]]) + 0.8

    # 2.建立线性回归模型，1个特征，1个权重，1一个偏置 y=xw+b
    # 随机给一个权重和偏置的值，让他去计算损失，然后再当前状态下优化
    weight = tf.Variable(tf.random_normal([1,1], mean=0.0, stddev= 1.0, name='w'))
    bias = tf.Variable(0.0, name='b')

    y_predict = tf.matmul(x, weight) + bias

    # 3.建立损失函数，均方误差
    loss = tf.reduce_mean(tf.square(y_true - y_predict))

    # 4.梯度下降优化损失 learning_rate: 0~1,2,3,4,5,6,7 10
    train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

    # 定义一个初始化变量op
    init_op = tf.global_variables_initializer()

    # 通过会话执行程序
    with tf.Session() as sess:
        # 初始化变量
        sess.run(init_op)
        # 打印随机最先初始化的权重和偏置
        print("随机初始化的参数权重为：%f,偏置为%f" %(weight.eval(), bias.eval()))

        # 运行优化
        sess.run(train_op)
        print("参数权重为：%f,偏置为：%f" %(weight.eval(),bias.eval()))
    return None


if __name__== '__main__':
    myregression()

    
 """
随机初始化的参数权重为：-0.317513,偏置为0.000000
参数权重为：0.683074,偏置为：0.526470
 
 """
```

循环1000次后的结果：

```python
# coding: utf-8
import tensorflow as tf


def myregression():

    # 1.准备数据，x 特征值[100,1] y目标值[100]
    x = tf.random_normal([100,1], mean=1.75,stddev=0.5,name='x_data')
    # 矩阵相乘必须是二维的
    y_true = tf.matmul(x,[[0.7]]) + 0.8

    # 2.建立线性回归模型，1个特征，1个权重，1一个偏置 y=xw+b
    # 随机给一个权重和偏置的值，让他去计算损失，然后再当前状态下优化
    weight = tf.Variable(tf.random_normal([1,1], mean=0.0, stddev= 1.0, name='w'))
    bias = tf.Variable(0.0, name='b')

    y_predict = tf.matmul(x, weight) + bias

    # 3.建立损失函数，均方误差
    loss = tf.reduce_mean(tf.square(y_true - y_predict))

    # 4.梯度下降优化损失 learning_rate: 0~1,2,3,4,5,6,7 10
    train_op = tf.train.GradientDescentOptimizer(0.1).minimize(loss)

    # 定义一个初始化变量op
    init_op = tf.global_variables_initializer()

    # 通过会话执行程序
    with tf.Session() as sess:
        # 初始化变量
        sess.run(init_op)
        # 打印随机最先初始化的权重和偏置
        print("随机初始化的参数权重为：%f,偏置为%f" %(weight.eval(), bias.eval()))
        # 循环训练，运行优化
        for i in range(1000):
            sess.run(train_op)
            print("参数权重为：%f,偏置为：%f" %(weight.eval(),bias.eval()))
    return None


if __name__== '__main__':
    myregression()
    
"""
参数权重为：0.699999,偏置为：0.800001
参数权重为：0.699999,偏置为：0.800001
参数权重为：0.699999,偏置为：0.800001
参数权重为：0.699999,偏置为：0.800001
参数权重为：0.699999,偏置为：0.800001
参数权重为：0.699999,偏置为：0.800001(取最后几次的结果来看)
"""
```

**tensorflow变量作用域：**

tf.Variable_scope(<scope_name>)创建指定名字的变量作用域
加上之后，代码会变得清爽，tensorboard中的图像结构也会变得清晰：

**增加变量显示：**

<img src="{{ site.url }}/assets//blog_images/ML/线性回归学习_02.png" />

**模型的保存和加载：**

<img src="{{ site.url }}/assets//blog_images/ML/线性回归学习_03.png" />

```python
saver = tf.train.Saver()
    # 通过会话执行程序
    with tf.Session() as sess:
        # 初始化变量
        sess.run(init_op)
        # 打印随机最先初始化的权重和偏置
        print("随机初始化的参数权重为：%f,偏置为%f" %(weight.eval(), bias.eval()))
        # 建立事件文件：
        filewriter = tf.summary.FileWriter('./test/', graph=sess.graph)
        # 循环训练，运行优化
        for i in range(500):
            sess.run(train_op)
            print("参数权重为：%f,偏置为：%f" %(weight.eval(),bias.eval()))

        saver.save(sess,'./test/ckpt/model')
```

```python
# 核心代码就是:先在with之前定义
saver = tf.train.Saver()
saver.save(sess.'路径')
```

加载模型：

```python
# 加载模型，覆盖模型当中随机定义的参数，从上次训练的参数结果开始
        if os.path.exists('./test/ckpt/'):
            saver.restore(sess,'./test/ckpt/model')
```

自定义命令行参数：

1.首先定义有哪些参数，需要在运行的时候指定

2.程序当中获取定义命令行参数

```python
# 第一个参数： 名字， 默认值， 说明
tf.app.flags.DEFINE_interger("max_step", 100, "模型训练的步数")
tf.app.flags.DEFINE_string("model_dir", " ", "模型文件的加载路径")

# 定义获取命令行参数名字
FLAGS = tf.app.flags.FLAGS 
```



















