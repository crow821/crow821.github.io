---
title: 统计学习方法（李航）笔记一
categories:
- 机器学习
tags:
- 统计学习方法
updated: 2018-11-18
---

### 第一章 统计学习方法概论

统计和概率的不同之处:

“概率”是已知了模型，预测下一个新数据的结果。“统计”是已知数据，归纳出模型。 

#### 统计学习的主要特点是

（1）平台--------计算机及网络，是建立在计算机及网络之上的；
（2）研究对象--------数据，是数据驱动的学科；
（3）目的---------对数据进行预测与分析；
（4）中心---------方法，统计学习方法构建模型并应用模型进行测试与分析；

 （5）交叉学科--------概率论、统计学、信息论、计算理论、最优化理论以及计算机科学等多个领域的交叉学科

#### 统计学习的对象

  面向的研究对象就是数据

 			<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_01.png" />

#### 统计学习方法的分类

  		监督学习(supervised leaning)
  		无监督学习(unsupervised leaning)
 		 半监督学习(semi-supervised leaning)
  		强化学习(reinfoucement leaning)


#### 统计学方法的三个要素

​	 统计学习方法=模型（model）+策略（strategy）+算法（algorithm）
	 模型：找到一个能够解决问题的条件概率或者决策函数。
	 策略：找到一个能够可以优化模型（或者衡量模型的）损失函数（比如0-1损失）。
 	算法：找到一种可以优化损失函数的方法（比如：梯度下降法）。


#### 统计学方法的步骤

​	 1  得到一个有限的训练数据集
	 2 确定假设空间（即所有可能的模型）
	 3 确定选择模型的准则（即策略）
 	4 实现求解最优化模型的算法（即算法）
 	5 选择最优模型

​       6 利用最优模型对新来的数据进行预测和分析

统计学习的研究
统计学习方法的研究——发现新的学习方法
统计学习理论的研究——提高统计学习方法的有效性和效率
统计学习应用的研究——-将统计学习方法应用到实际问题中去，解决实际问题。

#### 监督学习/supervised leaning

监督学习是本书的主要学习


监督学习也可以叫做有指导的学习，（在老师的指导和监督下学习，你会学的更好）所以，一般情况下，监督学习模型要优于无监督学习模型。当然会以需要训练集来作为代价，也就是说监督学习比无监督学习需要更多的资源（毕竟需要指导）。

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_02.png" />

假设输入实例X的特征向量记作 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_03.png" />

训练集： 假设输入变量用X表示，输出变量用Y表示，并假设输入与输出的随机变量X和Y满足联合概率分布P(X,Y)，监督学习问题的模型如下所示 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_04.png" />

可以理解为：将训练集输入到我们的学习系统—->根据决策方法学习一个最优的模型—–>利用这个最优的模型对新来的数据进行预测。

根据输入、输出变量的不同可以把预测任务分为以下三类：

回归问题-----输入变量与输出变量均为连续变量的预测问题；
分类问题------输出变量为有限个离散变量的预测问题；
标注问题------输入变量与输出变量均为变量序列的预侧问题.

他们的问题模型只需要把上图中的“预测系统”改为“分类系统”、“标注系统”即可

#### 三要素

##### **模型**

在监督学习过程中，模型就是所要学习的条件概率或者决策函数。 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_05.png" />

#####  策略

##### 损失函数和风险函数 

##### 损失函数(loss function)或代价函数(cost function)是用来度量模型的预测能力的。损失函数是 f (X)（预测值）和Y（真实值）之间的非负实值函数（因为两者之间的差值可以理解为两者之间的距离，是非负的。），记作L(Y, f (X)) 。

常用损失函数：

  (1)0-1损失函数(0-1 loss function)

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_06.png" />

 (2)平方损失函数 (quadratic loss function) 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_07.png" />

(3)绝对损失函数 (absolute loss function) 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_08.png" />

(4)对数损失函数(logarithmic loss function)或对数似然损失函数 (loglikehood loss function) 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_09.png" />

当然还存在其他的损失函数比如：指数损失函数或者Hinge Loss等。损失函数值越小，代表模型越好，模型出现的误差越小。  

**经验损失或者经验风险**  由于模型的输入、输出（X,Y）是随机变量，遵循联合分布P(X,Y),所以损失函数的期望是：  

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_10.png" />

这是理论上模型f (X)关于联合分布P(X,Y)的平均意义下的损失，称为风险函数(risk function)或期望损失(expected loss)。学习的日标就是选择期望风险最小的模型。由于，一方面根据期望风险最小化模型要用到联合概率分布，另一方面联合分布又是未知的，所以监督学习就成为一个病态问题！ 
在此我们提出另外一个概念：经验风险。(根据我自己的理解，带有“经验”的东东，一般是平均意义下东东，毕竟经验是需要积累的嘛。) 

模型f(x)关于训练数据集的平均损失称为经验风险(empirical risk)或经验损失(empirical loss): 

 <img src="{{ site.url }}/assets//blog_images/统计学习笔记1_11.png" />

期望风险Rexp(f)是模型关于联合分布的**期望损失**，经验风险Remp(f)是模型关于训练样本集的平均损失。根据大数定律，当样本容量N趋于无穷时，经验风险趋于期望风险。所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正.这就关系到监督学习的两个基本策略:经验风险最小化和结构风险最小化.

经验风险最小化(empirical risk minimization, ERM)，即求解最优化问题： 

 <img src="{{ site.url }}/assets//blog_images/统计学习笔记1_12.png" />

当样本容量足够大时，经验风险最小化能保证有很好的学习效果（比如一个人的经验积累越多，判别力肯定会越好）但是当样本容量很小的时候，经验风险最小化的学习效果未必很好（毕竟走过的路有点小，以为世界就那么大，所以很容易做出错误的判断），可能会产生“过拟合（over-fitting）”现象。因此这时需要结构风险最小化。

**结构风险最小化(structural risk minimization, SRM)是为了防止过拟合，在经验风险上加上表示模型复杂度的正则化项(regulatizer)或罚项(penalty term )，定义是：** 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_13.png" />

**算法**
学习模型的具体计算方法。统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问 
题的算法。**如何找到全局最优解并使得求解的过程非常高效！**

训练误差与测试误差
一般情况下，我们将数据集分为两大类：训练集和测试集。（有的时候分成三部分：训练集、验证集、测试集）。 

训练误差是指模型在训练集上的误差，反映的是模型的学习能力。 

 <img src="{{ site.url }}/assets//blog_images/统计学习笔记1_14.png" />

**过拟合**

##### 过拟合(over-fitting)：如果一味追求提高对训练数据的预侧能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合(over-fitting)。过拟合是指学习时选择的模型对己知数据（训练数据集中的数据）预测得很好，但对未知数据（测试数据集中的数据）预测得很差的现象。
 <img src="{{ site.url }}/assets//blog_images/统计学习笔记1_15.png" />

上面的例子是，根据数据分布拟合多项式模型，M代表模型的多项式次数，我们可以看到M=0和M=1的时候，模型的学习和预测能力都不好，而M=9的时候，模型的学习能力很好（几乎都学会了，也就是说拟合出的多项式模型，可以通过每个训练数据样本点），但是它的预测能力很差！并且模型太复杂！而当M=3的时候，模型的学习能力和预测能力都是比较好的。（从图图像上直观的看到是，预测出的曲线模型和真实的曲线模型之间拟合度）。

#### 训练误差和测试误差与模型复杂度之间的关系

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_16.png" />

#### 模型的选择方法：正则化和交叉验证

**正则化**我们学过了，就是结构风险最小化策略的实现：

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_17.png" />

上式中的第二项就是我们的正则项（或者罚项）。

**交叉验证：**重复地使用数据，把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择.

**简单交叉验证** 
    首先随机地将己给数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型.
 **k-折交叉脸证(S-fold cross validation）**
     方法如下:首先随机地将已给数据切分为S个互不相交的大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均侧试误差最小的模型.
 留一文叉验证 (leave-one-out cross validation)

​     k-折交叉验证的特殊情形是k=N，N是给定数据集的容量。

##### 生成模型和判别模型

监督学习方法又可以分为生成方法(generative approach)和判别方法(discriminative approach).所学到的模型分别称为生成模型(geuemtive model)和判别模型(discriminative model)。生成方法由数据学习联合概率分布P(X,Y),然后求出条件概率分布P(YIX)作为预测的模型，即生成模型。 

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_18.png" />

这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系.典型的生成模型有:朴素贝叶斯法和隐马尔可夫模型。

**判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型.**判别方法关心的是对给定的输入X，应该预测什么样的输出Y.典型的判别模型包括k近邻法、感知机、决策树、逻辑斯谛回归模型、最大嫡模型、支持向量机、提升方法和条件随机场等。

给定输入X,生成模型不能直接预测出输出的y，需要计算之后，再比较（或者求出的是各种输出可能性的概率值，最大作为最终的求解结果），而判别模型可以直接给出预测结果y,（利用判断规则或者方法）

**生成方法的特点：**

  1、生成方法可以还原出联合概率分布P(X,Y)，而判别方法则不能；
 2、生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；
3、当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。

**判别方法的特点：**

1、直接学习的是条件概率P(Y|X)或决策函数f(X)，直接面对预测，往往学习的准确率更高；

2、由于直接学习P(Y|X)或f(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题.

#### 几种模型评估标准

<img src="{{ site.url }}/assets//blog_images/统计学习笔记1_19.png" />



TP(True Positive)——将正类预测为正类数(d); 

FN(False Negative)——将正类预测为负类数(c); 

FP(False Positive)——将负类预测为正类数(b): 

TN(True Negative)——将负类预测为负类数(a) 

**精确率** P(Positive)=TP/(TP+FP)=d/(d+b) 
**召回率R**（Positive）=TP/(TP+FN)=d/(d+c) 
F1（精确率和召回率的调和均值） 
F1(Positive)=(2*P*R)/(P+R)

同理可以求得P(Negative)、R(Negative)、F1(Negative) 
这三种度量一般用于检测模型对每一类别的检测或预测能力。 
对模型整体评估如有**准确率AC（accuracy）** 

AC=(a+d)/(a+b+c+d)(对角线元素，正类和负类都预测正确的样本数)/(样本总数) 

下面是10中最常见的统计学习方法的概括总结：

 <img src="{{ site.url }}/assets//blog_images/统计学习笔记1_20.png" />












